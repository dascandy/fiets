An alternate approach to dependencies

| Document # | DxxxxR0 |
| Date | 2020-02-17 |
| Targeted subgroups | SG15 Tooling |
| Reply-to | Peter Bindels <dascandy@gmail.com> |

# Abstract

The C++ committee is currently working on the SG15 Tooling TR, to be produced in the near future. In this, it hopes to capture the state of the tooling ecosystem surrounding C++, building and instrumenting it. Most of the C++ ecosystem starts with the assumption that all build systems must start with a hand-written description of the full build system, and that it is not possible to do anything else. Many further assumptions and expectations are seated in this assumption. The assumption is false, though - and in this paper I will explain how cpp-dependencies (2017) and Evoke (2019) form a static analysis tool and a build system based on the concept of not writing build scripts.

# Goal of this paper

The goal of this paper is to provide insight to the Committee how a different way of building C++ code works, what its advantages and disadvantages are, and to explore a section of the tooling landscape that offers advantages not found elsewhere, with restrictions that differ from what we are accustomed to.

# General description

## The issue of colliding header file names

The rationale behind Evoke and Cpp-dependencies is that for any part of a project, the includes referred to in any translation unit should map to a unique set of actual files that it can target. Most tools allow for non-unique include statements, where a file name referenced from an include statement can map to multiple files, where the actual file being included depends on the order of include paths passed to the tool. Non-interactive tools will pick the first findable file, while interactive tools usually ask the user to clarify which of the files found was meant.

In a more fundamental way, this is translated to confusion on the part of users. A given include can map to multiple files, so for each such include the user needs to know both which of the two files was intended, and which file is actually going to be included first. The definition of the order is stored inside the build definition files, which means that to understand the code (or at least, be certain their interpretation of it is correct) they need to read the build system definition written in an often unfamiliar format.

In a third way, with build systems slowly moving to a higher level of abstraction, this becomes impossible to specify. Multiple components available for use in a larger build system can collide in an inclusion namespace view, where only the component that ends up using it will experience the collision and be unable to fix it.

As an even worse example, multiple components can have an include for a particular file, which becomes ambiguous as their headers are being included. Concretely:

```
// a.h in component a
#include <common.h> // from component a_common
```

```
// b.h in component b
#include <common.h> // from component b_common
```

```
// c.cpp in component c
#include "a.h"
#include "b.h"
```

For component C, there is no way to make these includes work as both A and B include a file searched from the include path, they match in file name and will therefore pick the wrong file in one (or both) of these cases.

As C++ code bases go on to become older, use package managers and grow, these problems become worse and worse.

## Pseudo-collisions

In many cases the system as seen does not necessarily have a collision at this moment, but will have a collision in the very near term future. For example, consider an application that includes a file called "Windows.h" built on Linux, where this refers to its windowing system. While the file itself is not conflicting with other files in the same program at the moment, it does conflict with well-known include files available on other systems. It would help with future portability to at least be able to find out these kinds of issues before the whole program is written around them.

A similar problem occurs for some operating systems that did not ship headers required for portability at a time these headers were in otherwise widespread usage. Some third-party libraries will make a reimplementation of that header for these platforms to get the benefits of the standard header, at the downside that now multiple mutually-possibly-incompatible headers exist with the same name. In fact, for the platforms that should use the actual standard header, the user may now get this header instead.

## Dependencies maintained by humans

In code bases that have existed for longer than a couple of months translation units slowly accrete includes that point to files that used to be necessary for their compilation, but no longer are. In a similar vein, components accumulate dependencies to other components that have existed, but where the dependency no longer exists. Forgetting such a dependency results in a build error (*usually), but having an unused one does not. In fact, as many dependencies can be accidentally given as a transitive dependency to its users, not even all missing dependencies will result in a build error in the first place.

The root of this problem lies with having a task that is not directly related to the implementation of the system at hand, copying the dependencies implied by the set of includes needed into the build scripting, to be executed perfectly by a human. In the system that lead to the reason for me starting with this investigation, an estimated 60% of all component-level dependencies were wrong, both in the present-but-not-needed and needed-but-not-present category, occasionally interacting to produce a dependency that was provably not needed, but that broke the build if you tried to remove it.

# Exploring the design space

We assume that a project, be it from very small (one file) to very large (tens of thousands of files), has include statements that map to a single possible target, for each evaluation of the include statement. This includes applying a local lookup for quotation mark includes, but not considering the include paths that might be set up by a build system. 

Ignoring for a second the problem of not knowing build flags to invoke a compiler, so that the compiler can then give out dependency information (such as makedepend and clang-scan-deps require), this gives us a full graph of all files, which translation units exist in this space and to which include file they all resolve. Any lookups can be satisfied in full by the graph built up.

It is very hard to translate this information to a higher-level abstraction like CMakeFiles or other build systems, as nearly all build systems reason in terms of components, libraries or executables. We need to have a way to know which directories are the root of a component, and which are not.

In cpp-dependencies I\'ve used the existence of a file called "CMakeLists.txt" in a folder a tag for a component existing. It then includes any files beneath it, excluding those that have a CMakeLists closer to them. This provides a way to group files in components and determine component-level dependencies (target_link_libraries in CMake lingo). Knowing the include statements mapping to a given component\'s header files allows us to export a perfectly formatted `target_include_directories` (again in CMake lingo) as we know exactly which components need which include paths to make the build work. We know the full contents of the component, so we can even add `target_sources` for the component informing it of its sources.

For a great many component in our target system, this is sufficient information to make cpp-dependencies generate the CMakeLists from scratch. Running a quick check on our current system shows that 2100 out of 2650 CMakeLists (79.2 %) are automatically currently (re)generated by this tool. This is about the maximum I expect for such a code base, as there are many components doing odd things, system integration (that cpp-dependencies cannot detect), other programming languages (not supported by cpp-dependencies) and other quirks. In 495 cases (23.6% of generated cmakelists) there is a "CMakeAddon.txt" file that is included into the CMakeLists so users can add non-autodetectable properties. This is after a few years of working on the system; I stopped on that project in 2016 removing most of the bias I personally can have on that number.

|Count of files | Percentage | Status |
|-|-|-|
| 1605 | 60.6% | Fully autogenerated |
| 495 | 18.7% | Autogenerated with addons |
| 550 | 20.8% | Hand-written |

Of interest is to take these CMakeAddon files and see what kind of things are typically done that are not captured by the automatic generation. A short analysis of the desired additions to the generated CMakeLists (percentage compared to total autogenerated CMakeLists count):

|Count | Percentage | Type of addition |
|-|-|-|
|266|12.6%|target_link_libraries|
|176|8.3%|add_test_data|
|87|4.1%|add_dependencies mostly for grouping targets|
|35|1.6%|warning overrides|
|35|1.6%|custom_target|
|34|1.6%|target_include_directories|
|27|1.2%|custom_command|
|26|1.2%|test property setting|
|26|1.2%|package export|
|20|0.9%|target_compile_options|
|19|0.9%|target name override|
|10|0.4%|target_compile_definitions|
|9|0.4%|add_library|
|7|0.3%|code generation|
|3|0.1%|highly project specific commands|
|1|0.0%|export symbols|
|1|0.0%|add_executable|

First, note that this table captures the targets where most of the CMakeLists is autogenerateable. There are other targets that are not autogenerateable, and those most likely do these kinds of things more. The most notable is target_link_libraries, as these are the dependencies that it should autodetect. A small investigation reveals:

- 136 are because of having a non-componentized Boost import, with componentized target names.
- 43 are for unknown reasons (should be autodetected)
- 31 add generated code
- 17 explicitly add a Json library. 
- 14 add libraries to the libraries/executable in these file
- 8 are to work around an XCode bug (according to comment)
- 6 link to platform-specific libraries (like Android\'s log, or Linux\' dl libraries)
- 6 are for a one specific TU that is built and used multiple times in a single output

These may also be obsolete in cases - see the above reasoning on why we should not want to hand write this. Also note that sometimes multiple of these are in a single statement; the numbers will add up to slightly more than 266. This is for a large project built up over multiple decades, including any legacy still present in the CMakeLists. There are hundreds of developers working on the code base concurrently, with thousands of prior developers having worked on parts of it.

## What if...

Given a tool that can automatically generate CMakeLists if you tag your folders with an essentially content-free CMakeLists file, I set out to see how much of a project could be autogenerated. Starting with my local small projects and seeing if it can scale up, I started with making the projects out of only autogenerated code. There are a few challenges this brings up over what cpp-dependencies had before:

- Tagging folders with an empty CMakeLists.txt file confused people looking into my projects. I\'ve switched to the alternate option of having folders called "src" and "include" after online polls from vector-of-bool indicating these names are the most common (albeit not universal).
- Many headers will be not found inside a project. These fall into three categories: system headers, system package headers and algorithm failures. The system headers should be effectively ignored and the algorithm failures should be fixed. System package headers often need include paths and libraries to along with them - this set of information should be exportable so that something can look at it and find the appropriate information. For Evoke\'s scope this is a communication path to export the list of include statement paths that are not known to be system headers and that are not found within the project. 
- There is no point to specify if something should be an executable or a library. cpp-dependencies snoops this from the CMakeLists, and if not found would default to a library. If you lose the path to specify this, there needs to be something that decides. Luckily, there is a great heuristic for whether or not something is a library. If some other component includes the headers of this component, it must be a library. If no other component (or unit test) includes the headers of this component, it must be an executable. This sounds and feels like an impossible shortcut, but it works out in practice. The most common problem is stale dead code - if a library loses all users and has no unit tests, it will now compile as an executable. So far I\'ve decided I\'m happy with it pointing out stale dead code :-)
- All of the things specified above you can do inside a CMakeAddon file, are now impossible.

This lead me to find out the downsides of this workflow:

- For every build you want to invoke regeneration first. 
- The turnaround time is limited by the efficiency of the programs individually.
- A multi-step process lends itself terribly to a fully continuous build system.

This lead me to believe that a build system, taking the same parsing logic that cpp-dependencies has, and turning it into a full build system (essentially absorbing the function of cmake and ninja, insofar as they are used) would lead to a build system that allows me (and others) to be much more efficient. That system, if developed, then offers a path to using others with the same build targets as effectively "distributed ccache", allowing small and large companies to use all machines on the network to speed up builds. 

This is Evoke, derived from its design goals.

## Taking it into reality

## What about modules?

In order to compile modules, the build system is required to understand which source file produces the main BMI for a given module name, figure out how to generate this BMI, order all BMI generations in a directed acyclic graph and then execute the relevant commands in DAG order. This is an extraordinarily close match to how Evoke already handles regular source code. To support modules, it needed to learn to parse module statements in addition to the relevant preprocessor statements, handle the concept of preprocessing and translating imports and header unit includes to dependencies on the BMI.

# Evaluation of this approach

## Advantages

- The build system has a higher level of understanding of the build than a contemporary build system can have, opening space for features built on these understandings.
- Modifying or updating a component layout is trivial
- Build system knows enough about the code to inform IDEs
- No build system scripting to forget, learn or break
- Developers do not need to understand or read build scripts to know if a file will be included in the build
- Most projects are using a layout that is very close to this already.
- Single-tool allows daemon mode continuously building the code in the background
- Daemon mode allows use as distributed ccache
- Daemon mode allows use as IDE backend with two-way communication protocol
- Multi-target builds are natively supported (including in daemon mode) making for easy multi-platform code editing

## Disadvantages

- Diverging from the project norm is not possible
- Generated code that the tool does not understand is not possible / hard to add
- Packaging or reordering the build outputs is not possible.
- Platform specifics cannot be done in build scripting
- It is not possible to port Doom to its scripting language.

## Limitations

- Files cannot be excluded from any build
- Unused code causes the build to break
- Ambiguous include statements are not allowed
- Optional dependencies do not fit the model
- Generated code needs to be added to the tool explicitly


